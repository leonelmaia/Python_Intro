{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td width=15%><img src=\"./img/UGA.png\"></img></td>\n",
    "<td><center><h1>Refresher Course on Matrix Analysis and Optimization</h1></center></td>\n",
    "<td width=15%><a href=\"http://www.iutzeler.org\" style=\"font-size: 16px; font-weight: bold\">Franck Iutzeler</a> <a href=\"https://ljk.imag.fr/membres/Jerome.Malick/\" style=\"font-size: 16px; font-weight: bold\">Jerome Malick</a><br/> Fall. 2018 </td>\n",
    "</tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><div id=\"top\"></div>\n",
    "\n",
    "<center><a style=\"font-size: 40pt; font-weight: bold\">Chap. 2 - Refresher Course </a></center>\n",
    "\n",
    "<br/>\n",
    "\n",
    "# ``1. Matrix Analysis``\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#style\"><b>Package check and Styling</b></a><br/><br/><b>Outline</b><br/><br/>\n",
    "&nbsp;&nbsp;&nbsp; a) <a href=\"#MALinReg\"> Linear Systems Resolution with applications to Regression</a><br/>&nbsp;&nbsp;&nbsp; b) <a href=\"#MASVD\"> Singular Value Decomposition and Image Compression</a><br/>&nbsp;&nbsp;&nbsp; c) <a href=\"#MAPG\"> PageRank and the Power Method</a><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"MALinReg\"> a) Linear Systems Resolution with applications to Regression</a>  \n",
    "\n",
    "<p style=\"text-align: right; font-size: 10px;\"><a href=\"#top\">Go to top</a></p>\n",
    "\n",
    "\n",
    "\n",
    "In this example, we use linear algebra to extract information from data; more precisely, we predict final notes of a group of student from their profiles with the [Student Performance dataset](https://archive.ics.uci.edu/ml/datasets/Student+Performance) which includes secondary education students of two Portuguese schools.\n",
    "\n",
    "\n",
    "Profiles include features such as student grades, demographic, social and school related features and were collected by using school reports and questionnaires. There are $m = 395$ students (examples) and we selected $n = 27$ features (see <tt>data/student.txt</tt> for the features description and <tt>datat/student-mat.csv</tt> for the csv dataset.)\n",
    "\n",
    "\n",
    "\n",
    "Our goal is to predict a target feature (the $28$-th) which is the final grade of the student from the other features (the first $27$). We assume that the final grade can be explained by a linear combination of the other features. We are going to learn from this data using linear regression over the $m_{learn} = 300$ students (called the *learning set*). We will check our prediction by comparing the results for the other $m_{test} = 95$ students (the *testing set*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# File reading\n",
    "dat_file = np.load('data/student.npz')\n",
    "A_learn = dat_file['A_learn']\n",
    "b_learn = dat_file['b_learn']\n",
    "A_test = dat_file['A_test']\n",
    "b_test = dat_file['b_test']\n",
    "\n",
    "m = 395 # number of read examples (total:395)\n",
    "n = 27 # features\n",
    "m_learn = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematically, from the $m_{learn} \\times (n+1)$ *learning matrix* (the number of columns is $n+1$ as a column of ones, called *intercept* for statistical reasons). $A_{learn}$ comprising of the features values of each training student in line, and the vector of the values of the target features $b_{learn}$;  we seek a size-$n+1$ *regression vector* that minimizes the squared error between  $A_{learn} x$ and $b_{learn}$. This problem boils down to the following least square problem:\n",
    "$$ \\min_{x\\in\\mathbb{R}^{n+1}}  \\|  A_{learn} x - b_{learn} \\|_2^2 . $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exo\"> <b>Question 1:</b> Observe the rank of the $m_{learn} \\times (n+1)$ matrix $A_{learn}$. Does it have full row rank? full column rank? Conclude about the existence and uniqueness of solutions of the problem.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_A_learn = 0 #.........................................\n",
    "#print('Rank of matrix A_learn ({:d} rows, {:d} cols.): {:d}\\n'.format(m_learn,n+1,rank_A_learn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div class=\"exo\"> <b>Question 2:</b>Compute the solution of the minimization problem using the Singular Value Decomposition. <br/>* **hint:** use the option <tt>full_matrices=False</tt> of Numpy's SVD command to get the compact SVD.*</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_reg = np.linalg.lstsq(A_learn,b_learn)[0]\n",
    "\n",
    "\n",
    "U, s, Vt = np.linalg.svd(A_learn, full_matrices=False)\n",
    "A_pinv_svd  =  0 #.........................................\n",
    "x_reg_svd = 0 #........................................."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div class=\"exo\"> <b>Question 3:</b> In order to test the goodness of our predictor <tt>x_reg</tt>, we use the rest of the data to compare our predictions with the actual observations. The test matrix $A_{test}$ has $m_{test} = 95$ rows (students) and $n+1 = 28$ columns (features+intercept). Construct the predicted grades from <tt>x_reg</tt> and compare with the actual observed grades in $b_{test}$ (set <tt>SHOW_PREDICTION = True</tt> in the code). </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = 0 #.........................................\n",
    "\n",
    "SHOW_PREDICTION = False\n",
    "\n",
    "if SHOW_PREDICTION:\n",
    "    print('\\n\\n  Predicted | True value')\n",
    "    for i in range(predict.size):\n",
    "        print('\\t{:2d}     {:2d} '.format(int(predict[i]),int(b_test[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div class=\"exo\"> <b>Question 4:</b> Compare the relative values of the coefficients of the predictor <tt>x_reg</tt> (set  <tt>SHOW_PREDICTION = True</tt>  in the code). What can you observe about the relative importance of the features?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHOW_PREDICTOR  = False\n",
    "\n",
    "if SHOW_PREDICTOR:\n",
    "    filename = 'data/student.txt' \n",
    "    f = open(filename, 'r')\n",
    "    f.readline() # read the first (description) line\n",
    "    for i in range(n):\n",
    "        print(\"{:2.3f} \\t-- {:s}\".format(x_reg[i],f.readline()))\n",
    "    print(\"{:2.3f} \\t-- Intercept\".format(x_reg[n]))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"MASVD\"> b) Singular Value Decomposition and Image Compression</a>  \n",
    "\n",
    "<p style=\"text-align: right; font-size: 10px;\"><a href=\"#top\">Go to top</a></p>\n",
    "\n",
    "\n",
    "The goal of this exercise is to investigate the computational aspects of the SVD; and, more importantly, observing the fact that the greater the magnitude of the singular value, the greater the importance of the associated vectors in the matrix coefficients. Investigating on this latter property will be done through the SVD of the following image  seen as an array of grayscale values.\n",
    "\n",
    "\n",
    "<img src=\"img/flower.jpg\" alt=\"flower\" style=\"width: 30%;\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "\n",
    "#### IMAGE\n",
    "img = mpimg.imread('img/flower.png')\n",
    "img_gray =  0.2989 * img[:,:,0] + 0.5870 * img[:,:,1] + 0.1140 * img[:,:,2] # Apparently these are \"good\" coefficients to convert to grayscale\n",
    "#########"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, in matrix decomposition every part is bearer of information and even though eigenvalues provide useful informations on some properties of the matrix, the associated eigenvectors are needed for a full reconstruction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVD \n",
    "U, s, Vt = np.linalg.svd(img_gray, full_matrices=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exo\"> <b>Question 1:</b> In this question, we will put <tt>n\\_to\\_zero = 360</tt> of the singular values (this corresponds to $75\\%$ of the singular values) to zero while leaving the others unchanged; and construct new images from the modified singular values and the former matrices $U$ and $V$. In <tt>img_i</tt>, you will put the *smallest* singular values to zero; in <tt>img_ii</tt>, the greatest; and in <tt>img_iii</tt>, random ones.  Observe the difference between these three modifications. What do you notice?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compression percentage: number of eigenvalues set to zero - To modify\n",
    "Compression = 75.0  # in percents\n",
    "nb_to_zero = int(np.ceil(len(s)*Compression/100))  # Number of singular values to put to zero\n",
    "\n",
    "\n",
    "# (i) Nulling the smallest singular values\n",
    "\n",
    "img_i = 0 #.........................................\n",
    "\n",
    "\n",
    "# (ii) Nulling the greatest singular values\n",
    "\n",
    "img_ii = 0 #.........................................\n",
    "\n",
    "\n",
    "# (iii) Nulling random singular values\n",
    "\n",
    "img_iii = 0 #.........................................\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################\n",
    "## SHOW THE FIGURES\n",
    "print('The image is {:d}x{:d}\\n - it has {:d} singular values between {:.3f} and {:.3f}'.format( img_gray.shape[0], img_gray.shape[1]  , len(s)  ,  np.min(s) , np.max(s) ))\n",
    "print(' - {:.1f}% of the singular values are set to zero ({:d}/{:d})'.format(Compression ,  int(nb_to_zero) ,  len(s)   ))\n",
    "\n",
    "plt.figure()# new figure\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "plt.xticks([]),plt.yticks([])\n",
    "plt.title(\"Original\")\n",
    "plt.imshow(img_gray, cmap = cm.Greys_r) \n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.xticks([]),plt.yticks([])\n",
    "plt.title(\"(i) smallest\")\n",
    "#plt.imshow(img_i, cmap = cm.Greys_r) \n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.xticks([]),plt.yticks([])\n",
    "plt.title(\"(ii) greatest\")\n",
    "#plt.imshow(img_ii, cmap = cm.Greys_r) \n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.xticks([]),plt.yticks([])\n",
    "plt.title(\"(iii) random\")\n",
    "#plt.imshow(img_iii, cmap = cm.Greys_r) \n",
    "\n",
    "plt.show() #show the window\n",
    "###############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exo\"> <b>Question 2:</b> Compute the sum of the singular values for the original image and the three modified images. What can you conclude about the visual information provided by the singular values?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"MAPG\"> c) PageRank and the Power Method</a>  \n",
    "\n",
    "<p style=\"text-align: right; font-size: 10px;\"><a href=\"#top\">Go to top</a></p>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "In this part, we will compute the PageRank ordering of the following graph.\n",
    "\n",
    "\n",
    "<img src=\"img/graph.png\" alt=\"graph\" style=\"width: 50%;\"/>\n",
    "\n",
    "\n",
    "In PageRank, the score $x_i$ of page $i$ is equal to the sum over the pages $j$ pointing toward $i$ of their scores $x_j$  divided by their number of outgoing links $n_j$. This leads to a ranking matrix $R$ defined from the scoring method as\n",
    "$$ x = Rx.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#### Graph matrix\n",
    "A = np.array([[0,1,1,0,1],[0,0,0,1,1],[1,0,0,1,0],[0,0,1,0,1],[0,1,0,0,0]])\n",
    "####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exo\"> <b>Question 1:</b> Explain how the ranking matrix $R$ is generated from adjacence matrix $A$ in the following code. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  column stochatic normalization \n",
    "R = np.dot( A  , np.diag(1.0/np.sum(A,0)) ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exo\"> <b>Question 2:</b> Check numerically that $\\|R\\| = 1$ for some matrix norm and that the spectral radius of $R$ is equal to $1$. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_rad = 0 #.........................................\n",
    "#print(\"Spectral radius: {:f}\".format( sp_rad ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exo\"> <b>Question 3:</b> Iterate the matrix $R$ a large number of times and check if the matrix is primitive. What do you notice on the eigenvalues and eigenvectors? How is defined the rank 1 matrix that you obtain? This manner of computing eigenvectors/values is called the *power method*.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 100\n",
    "R_pow = 0 #.........................................\n",
    "eig_val_pow,eig_vec_pow = 0,0 #.........................................\n",
    "#print(\"R^{0} = {1}\".format(k,R_pow))\n",
    "#print(\"eigenvalues: {0}\".format(eig_val_pow))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exo\"> <b>Question 4:</b> Recover the *Perron* eigenvector of matrix $R$. The entries of this vector are the PageRank scores of the nodes/pages of the graph. Give the PageRank ordering of the pages of the graph.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = 0 #......................................... \n",
    "#print(\"Perron vector: {0}\".format(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exo\"> <b>Question 5: (to go further)</b> In this exercise, the graph we took led to a *primitive* matrix as seen above; this is necessary for the power method to work as the eigenvalue $1$ has to be the only one of modulus $1$. This is actually the case when the graph is strongly connected, that is when you can go from any node to any other node by following the edges, with *enough* loops. When it is not the case, our problem becomes ill posed. To overcome this problem, the ranking matrix $R$  is replaced by \n",
    "$$ M = (1-\\alpha) R + \\alpha J, ~~~~~~~~ \\alpha\\in]0,1[ $$\n",
    "where is $J$ is the $5\\times 5$ matrix whose entries are all $1/5$. The value of $\\alpha$ originally used by Google is $0.15$.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  \n",
    "  *  \n",
    "     *  Show that $M$ is column-stochastic provided that $R$ is.\n",
    "     *  Show that the problem is now well-posed.\n",
    "     *  Compute the ranking for the original graph but where the link from $2$ to $5$ is suppressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### New Graph matrix\n",
    "A_2 = np.array([[0,1,1,0,1],[0,0,0,1,1],[1,0,0,1,0],[0,0,1,0,1],[0,0,0,0,0]])\n",
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div id=\"style\"></div>\n",
    "### Package Check and Styling\n",
    "\n",
    "\n",
    "<p style=\"text-align: right; font-size: 10px;\"><a href=\"#top\">Go to top</a></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib.notebook_setting as nbs\n",
    "\n",
    "packageList = ['IPython', 'numpy', 'scipy', 'matplotlib', 'cvxopt']\n",
    "nbs.packageCheck(packageList)\n",
    "\n",
    "nbs.cssStyling()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
